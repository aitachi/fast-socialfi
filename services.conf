# ===========================================
# Fast SocialFi - 统一服务配置文件
# ===========================================
# 本文件包含所有 Docker 服务的详细配置信息
# 最后更新: 2025-11-02

# ===========================================
# 1. PostgreSQL 配置
# ===========================================
[postgresql]
service_name = PostgreSQL Database
container_name = socialfi-postgres
image = postgres:16-alpine
version = 16

# 连接信息
host = localhost
port = 5432
database = socialfi_db
username = socialfi
password = socialfi_pg_pass_2024

# 连接 URL
connection_url = postgresql://socialfi:socialfi_pg_pass_2024@localhost:5432/socialfi_db

# 性能配置
max_connections = 200
shared_buffers = 256MB
effective_cache_size = 1GB
work_mem = 1310kB

# 数据持久化
data_volume = postgres_data
data_path_in_container = /var/lib/postgresql/data

# 健康检查
healthcheck_interval = 10s
healthcheck_timeout = 5s
healthcheck_retries = 5

# 重启策略
restart_policy = always

# ===========================================
# 2. Redis 配置
# ===========================================
[redis]
service_name = Redis Cache
container_name = socialfi-redis
image = redis:7-alpine
version = 7

# 连接信息
host = localhost
port = 6379
password = socialfi_redis_2024

# 连接 URL
connection_url = redis://:socialfi_redis_2024@localhost:6379

# 内存配置
maxmemory = 256mb
maxmemory_policy = allkeys-lru

# 持久化配置
persistence_mode = AOF + RDB
appendonly = yes
appendfsync = everysec
save_intervals = 900 1, 300 10, 60 10000

# 数据持久化
data_volume = redis_data
data_path_in_container = /data

# 配置文件
config_file = ./redis.conf

# 健康检查
healthcheck_interval = 10s
healthcheck_timeout = 5s
healthcheck_retries = 5

# 重启策略
restart_policy = always

# ===========================================
# 3. Elasticsearch 配置
# ===========================================
[elasticsearch]
service_name = Elasticsearch
container_name = socialfi-elasticsearch
image = elasticsearch:8.11.3
version = 8.11.3

# 连接信息
host = localhost
http_port = 9200
transport_port = 9300

# HTTP 连接 URL
http_url = http://localhost:9200

# 集群配置
node_name = socialfi-es-node
cluster_name = socialfi-cluster
discovery_type = single-node

# 安全配置 (已禁用以便开发)
xpack_security_enabled = false
xpack_security_http_ssl_enabled = false
xpack_security_transport_ssl_enabled = false

# JVM 配置
java_heap_min = 512m
java_heap_max = 512m
es_java_opts = -Xms512m -Xmx512m

# 数据持久化
data_volume = es_data
data_path_in_container = /usr/share/elasticsearch/data

# 资源限制
memlock_soft = -1
memlock_hard = -1
nofile_soft = 65536
nofile_hard = 65536

# 健康检查
healthcheck_interval = 30s
healthcheck_timeout = 10s
healthcheck_retries = 5
healthcheck_start_period = 60s

# 重启策略
restart_policy = always

# ===========================================
# 4. Kafka 配置 (KRaft 模式)
# ===========================================
[kafka]
service_name = Apache Kafka (KRaft Mode)
container_name = socialfi-kafka
image = apache/kafka:3.7.0
version = 3.7.0
mode = KRaft (No ZooKeeper)

# 连接信息
host = localhost
broker_port = 9092
controller_port = 9093

# Bootstrap Servers
bootstrap_servers = localhost:9092

# KRaft 配置
node_id = 1
process_roles = broker,controller
cluster_id = MkU3OEVBNTcwNTJENDM2Qk

# 监听器配置
listeners = PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
advertised_listeners = PLAINTEXT://localhost:9092
listener_security_protocol_map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
inter_broker_listener_name = PLAINTEXT

# 副本配置
offsets_topic_replication_factor = 1
transaction_state_log_replication_factor = 1
transaction_state_log_min_isr = 1

# 性能配置
group_initial_rebalance_delay_ms = 0
java_heap_min = 512M
java_heap_max = 512M

# 数据持久化
data_volume = kafka_data
log_dirs = /var/lib/kafka/data

# 健康检查
healthcheck_interval = 30s
healthcheck_timeout = 10s
healthcheck_retries = 5
healthcheck_start_period = 40s

# 重启策略
restart_policy = always

# ===========================================
# 5. Kafka UI 配置
# ===========================================
[kafka-ui]
service_name = Kafka UI (Web Management)
container_name = socialfi-kafka-ui
image = provectuslabs/kafka-ui:latest
version = latest

# 访问信息
web_ui_url = http://localhost:8090
port = 8090

# Kafka 连接配置
kafka_cluster_name = socialfi-cluster
kafka_bootstrap_servers = kafka:9092

# 重启策略
restart_policy = always

# ===========================================
# 网络配置
# ===========================================
[network]
network_name = socialfi-network
driver = bridge

# 容器间通信
# 容器内部可以通过服务名直接访问，例如:
# - postgres:5432
# - redis:6379
# - elasticsearch:9200
# - kafka:9092

# ===========================================
# Docker Compose 配置文件
# ===========================================
[docker-compose]
config_file = docker-compose.full.yml
project_name = fast-socialfi

# 启动命令
start_command = docker-compose -f docker-compose.full.yml up -d
stop_command = docker-compose -f docker-compose.full.yml down
restart_command = docker-compose -f docker-compose.full.yml restart
logs_command = docker-compose -f docker-compose.full.yml logs -f
status_command = docker-compose -f docker-compose.full.yml ps

# ===========================================
# 端口映射总览
# ===========================================
[ports]
# 格式: 服务名 = 宿主机端口:容器端口
PostgreSQL = 5432:5432
Redis = 6379:6379
Elasticsearch_HTTP = 9200:9200
Elasticsearch_Transport = 9300:9300
Kafka_Broker = 9092:9092
Kafka_Controller = 9093:9093
Kafka_UI = 8090:8080

# ===========================================
# 数据卷总览
# ===========================================
[volumes]
postgres_data = PostgreSQL 数据
redis_data = Redis 持久化数据
es_data = Elasticsearch 索引数据
kafka_data = Kafka 日志和数据

# 查看数据卷命令
list_volumes = docker volume ls | grep socialfi
inspect_volume = docker volume inspect <volume_name>

# ===========================================
# 自动启动配置
# ===========================================
[autostart]
# Windows
windows_startup_script = startup-all-services.bat
windows_startup_location = %APPDATA%\Microsoft\Windows\Start Menu\Programs\Startup

# Ubuntu/Linux
ubuntu_systemd_service = docker-socialfi.service
ubuntu_service_location = /etc/systemd/system/
ubuntu_enable_command = sudo systemctl enable docker-socialfi.service

# Docker Desktop
docker_desktop_autostart = 需要在 Docker Desktop 设置中启用
docker_desktop_setting_path = Settings > General > Start Docker Desktop when you log in

# ===========================================
# 健康检查端点
# ===========================================
[health-endpoints]
PostgreSQL = docker exec socialfi-postgres pg_isready -U socialfi
Redis = docker exec socialfi-redis redis-cli ping
Elasticsearch = curl http://localhost:9200/_cluster/health
Kafka = docker exec socialfi-kafka kafka-broker-api-versions.sh --bootstrap-server localhost:9092

# ===========================================
# 快速连接命令
# ===========================================
[connect-commands]
PostgreSQL = docker exec -it socialfi-postgres psql -U socialfi -d socialfi_db
Redis = docker exec -it socialfi-redis redis-cli -a socialfi_redis_2024
Elasticsearch = curl http://localhost:9200/_cat/indices?v
Kafka_Create_Topic = docker exec socialfi-kafka kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092
Kafka_List_Topics = docker exec socialfi-kafka kafka-topics.sh --list --bootstrap-server localhost:9092
Kafka_UI = http://localhost:8090

# ===========================================
# 备份命令
# ===========================================
[backup-commands]
PostgreSQL = docker exec socialfi-postgres pg_dump -U socialfi socialfi_db > backup_$(date +%Y%m%d).sql
Redis = docker exec socialfi-redis redis-cli -a socialfi_redis_2024 SAVE && docker cp socialfi-redis:/data/dump.rdb backup_redis_$(date +%Y%m%d).rdb
Elasticsearch = curl -X POST "localhost:9200/_snapshot/my_backup/snapshot_$(date +%Y%m%d)?wait_for_completion=true"
Kafka = 需要配置 Kafka Mirror Maker 或使用 Kafka Connect

# ===========================================
# 应用程序连接示例 (Node.js)
# ===========================================
[nodejs-examples]
# PostgreSQL
postgresql_example = const { Pool } = require('pg'); const pool = new Pool({ host: 'localhost', port: 5432, database: 'socialfi_db', user: 'socialfi', password: 'socialfi_pg_pass_2024' });

# Redis
redis_example = const redis = require('redis'); const client = redis.createClient({ url: 'redis://:socialfi_redis_2024@localhost:6379' });

# Elasticsearch
elasticsearch_example = const { Client } = require('@elastic/elasticsearch'); const client = new Client({ node: 'http://localhost:9200' });

# Kafka
kafka_example = const { Kafka } = require('kafkajs'); const kafka = new Kafka({ brokers: ['localhost:9092'], clientId: 'socialfi-app' });

# ===========================================
# 环境变量文件
# ===========================================
[env-file]
# 可以创建 .env 文件存放敏感信息
env_file_path = .env

# 示例内容:
# POSTGRES_PASSWORD=socialfi_pg_pass_2024
# REDIS_PASSWORD=socialfi_redis_2024
# KAFKA_CLUSTER_ID=MkU3OEVBNTcwNTJENDM2Qk

# ===========================================
# 监控和日志
# ===========================================
[monitoring]
# 查看所有容器状态
status = docker-compose -f docker-compose.full.yml ps

# 查看资源使用
stats = docker stats

# 查看特定服务日志
postgres_logs = docker logs -f socialfi-postgres
redis_logs = docker logs -f socialfi-redis
elasticsearch_logs = docker logs -f socialfi-elasticsearch
kafka_logs = docker logs -f socialfi-kafka

# ===========================================
# 故障排除
# ===========================================
[troubleshooting]
# 重启所有服务
restart_all = docker-compose -f docker-compose.full.yml restart

# 重启单个服务
restart_one = docker-compose -f docker-compose.full.yml restart <service_name>

# 查看容器详情
inspect = docker inspect <container_name>

# 进入容器
exec_postgres = docker exec -it socialfi-postgres sh
exec_redis = docker exec -it socialfi-redis sh
exec_elasticsearch = docker exec -it socialfi-elasticsearch bash
exec_kafka = docker exec -it socialfi-kafka bash

# 完全重置 (会删除所有数据!)
reset_all = docker-compose -f docker-compose.full.yml down -v && docker-compose -f docker-compose.full.yml up -d
